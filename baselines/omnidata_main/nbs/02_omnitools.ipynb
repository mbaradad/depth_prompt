{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "from omnidata_tools.dataset.download import download\n",
    "from fastcore.script import anno_parser\n",
    "import os\n",
    "os.environ[\"COLUMNS\"] = '100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# omnitools CLI\n",
    "\n",
    "> Tools to efficiently download/upload/move annotator data. <code>pip install 'omnidata-tools'</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `omnitools.download`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`omnitools.download` is a one-line utility for rapidly downloading the starter (& similar) datasets.** \n",
    "\n",
    "The download tool is designed to be fast and easy to use (it's built off of [aria2](https://aria2.github.io/)). We regularly get 70MB/s downloading from the EPFL servers to Berkeley. It's written pretty generally, too, so the tool can also be used to download other datasets stored in a similar format (i.e. other datasets formatted similarly to annotator outputs, like [Taskonomy](//taskonomy.stanford.edu)).\n",
    "<br>**_Note:_** There's also an inverse **`omnitools.upload`** for uploading an annotator-generated dataset to a server.\n",
    "\n",
    "Here is the `man` page for the tool:\n",
    "```bash\n",
    "> omnitools.download -h\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: omnitools.download [-h] [--subset {debug,tiny,medium,full,fullplus}]\n",
      "                          [--split {train,val,test,all}]\n",
      "                          [--components {all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} [{all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} ...]]\n",
      "                          [--dest DEST] [--dest_compressed DEST_COMPRESSED]\n",
      "                          [--keep_compressed KEEP_COMPRESSED] [--only_download ONLY_DOWNLOAD]\n",
      "                          [--max_tries_per_model MAX_TRIES_PER_MODEL]\n",
      "                          [--connections_total CONNECTIONS_TOTAL]\n",
      "                          [--connections_per_server_per_download CONNECTIONS_PER_SERVER_PER_DOWNLOAD]\n",
      "                          [--n_workers N_WORKERS] [--num_chunk NUM_CHUNK]\n",
      "                          [--num_total_chunks NUM_TOTAL_CHUNKS] [--ignore_checksum IGNORE_CHECKSUM]\n",
      "                          [--dryrun] [--aria2_uri ARIA2_URI]\n",
      "                          [--aria2_cmdline_opts ARIA2_CMDLINE_OPTS]\n",
      "                          [--aria2_create_server ARIA2_CREATE_SERVER] [--aria2_secret ARIA2_SECRET]\n",
      "                          [--agree_all]\n",
      "                          domains [domains ...]\n",
      "\n",
      "Downloads Omnidata starter dataset. --- The data is stored on the remote server in a compressed\n",
      "format (.tar.gz). This function downloads the compressed and decompresses it. Examples: download rgb\n",
      "normals point_info --components clevr_simple clevr_complex --connections_total 30\n",
      "\n",
      "positional arguments:\n",
      "  domains                                         Domains to download (comma-separated or 'all')\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help                                      show this help message and exit\n",
      "  --subset {debug,tiny,medium,full,fullplus}      Subset to download (default: debug)\n",
      "  --split {train,val,test,all}                    Split to download (default: all)\n",
      "  --components {all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} [{all,replica,taskonomy,gso_in_replica,hypersim,blendedmvs,hm3d,clevr_simple,clevr_complex} ...]\n",
      "                                                  Component datasets to download (comma-separated)\n",
      "                                                  (default: all)\n",
      "  --dest DEST                                     Where to put the uncompressed data (default:\n",
      "                                                  uncompressed/)\n",
      "  --dest_compressed DEST_COMPRESSED               Where to download the compressed data (default:\n",
      "                                                  compressed/)\n",
      "  --keep_compressed KEEP_COMPRESSED               Don't delete compressed files after decompression\n",
      "                                                  (default: False)\n",
      "  --only_download ONLY_DOWNLOAD                   Only download compressed data (default: False)\n",
      "  --max_tries_per_model MAX_TRIES_PER_MODEL       Number of times to try to download model if\n",
      "                                                  checksum fails. (default: 3)\n",
      "  --connections_total CONNECTIONS_TOTAL           Number of simultaneous aria2c connections overall\n",
      "                                                  (note: if not using the RPC server, this is per-\n",
      "                                                  worker) (default: 8)\n",
      "  --connections_per_server_per_download CONNECTIONS_PER_SERVER_PER_DOWNLOAD\n",
      "                                                  Number of simulatneous aria2c connections per\n",
      "                                                  server per download. Defaults to\n",
      "                                                  'total_connections' (note: if not using the RPC\n",
      "                                                  server, this is per-worker)\n",
      "  --n_workers N_WORKERS                           Number of workers to use (default: 32)\n",
      "  --num_chunk NUM_CHUNK                           Download the kth slice of the overall dataset\n",
      "                                                  (default: 0)\n",
      "  --num_total_chunks NUM_TOTAL_CHUNKS             Download the dataset in N total chunks. Use with '\n",
      "                                                  --num_chunk' (default: 1)\n",
      "  --ignore_checksum IGNORE_CHECKSUM               Ignore checksum validation (default: False)\n",
      "  --dryrun                                        Keep compressed files even after decompressing\n",
      "                                                  (default: False)\n",
      "  --aria2_uri ARIA2_URI                           Location of aria2c RPC (if None, use CLI)\n",
      "                                                  (default: http://localhost:6800)\n",
      "  --aria2_cmdline_opts ARIA2_CMDLINE_OPTS         Opts to pass to aria2c (default: )\n",
      "  --aria2_create_server ARIA2_CREATE_SERVER       Create a RPC server at aria2_uri (default: True)\n",
      "  --aria2_secret ARIA2_SECRET                     Secret for aria2c RPC (default: )\n",
      "  --agree_all                                     Agree to all license clickwraps. (default: False)\n"
     ]
    }
   ],
   "source": [
    "#hide_input\n",
    "argparser = anno_parser(download)\n",
    "argparser.prog = 'omnitools.download'\n",
    "argparser.print_help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `omnitools.upload`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
